#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass beamer
\begin_preamble
\usepackage{dcolumn}
\usepackage{booktabs}
\usepackage{array}
\usepackage{longtable}
\usepackage{graphicx}
\renewcommand{\doiprefix}{doi:\kern-1pt}
\setlength{\bibsep}{10pt}

% use 'handout' to produce handouts
%\documentclass[handout]{beamer}
\usepackage{wasysym}
\usepackage{pgfpages}
%for bold upright roman in math for matrix algebra
\newcommand{\vn}[1]{\mbox{{\it #1}}}\newcommand{\vb}{\vspace{\baselineskip}}\newcommand{\vh}{\vspace{.5\baselineskip}}\newcommand{\vf}{\vspace{\fill}}\newcommand{\splus}{\textsf{S-PLUS}}\newcommand{\R}{\textsf{R}}

%%\input{theme/guidePreambleSweavel.tex} 
%%% From beamer slide:
\usepackage{Sweave}
%% 
%% This controls display of code chunks
\usepackage{ae,fancyvrb,relsize,listings}

\providecommand{\Sweavesize}{\normalsize}
\providecommand{\Rsize}{}
\renewcommand{\Rsize}{\normalsize}
\providecommand{\Routsize}{\scriptsize}

\providecommand{\Rcolor}{\color[rgb]{0.1, 0.1, 0.1}}
\providecommand{\Routcolor}{\color[rgb]{0.2, 0.2, 0.2}}
\providecommand{\Rcommentcolor}{\color[rgb]{0.101, 0.43, 0.432}}

\providecommand{\Rbackground}{\color[gray]{0.91}}
\providecommand{\Routbackground}{\color[gray]{0.935}}
% Can specify \color[gray]{1} for white background or just \color{white}

\lstdefinestyle{Rinput}{
  language=R,
  escapechar=`,
  fancyvrb=false,%
  tabsize=2,%
  breaklines=true,
  breakatwhitespace=true,%
  captionpos=b,%
  frame=single,%
  framerule=0.2pt,%
  framesep=1pt,%
  showstringspaces=false,%
  basicstyle=\Rsize\Rcolor\ttfamily,%
  columns=fixed%,
  \lst@ifdisplaystyle\scriptsize\fi,%,
  commentstyle=\Rcommentcolor\ttfamily,%
  identifierstyle=,%
  keywords=\bfseries,%
  keywordstyle=\color[rgb]{0, 0.5, 0.5},
  escapeinside={(*}{*)},
  literate={~}{{$\sim$}}1{==}{{=\,=}}2{--}{{-\,-}}2,
  alsoother={$},
  alsoletter={.<-},%
  otherkeywords={!,!=,~,$$,*,\&,\%/\%,\%*\%,\%\%,<-,<<-,/},%
  backgroundcolor=\Rbackground,%
  numbers=left,%
  %numberblanklines=false,%
  stepnumber=5,
  firstnumber=1,
  numberstyle={\tiny}
}%

% Other options of interest:
% frame=single,framerule=0.1pt,framesep=1pt,rulecolor=\color{blue},
% numbers=left,numberstyle=\tiny,stepnumber=1,numbersep=7pt,
% keywordstyle={\bf\Rcolor}

\lstdefinestyle{Routput}{fancyvrb=false,
  literate={~}{{$\sim$}}1{R^2}{{$R^{2}$}}2{^}{{$^{\scriptstyle\wedge}$}}1{R-squared}{{$R^{2}$}}2,%
  basicstyle=\Routcolor\Routsize\ttfamily,%
  backgroundcolor=\Routbackground,
  language=R,
  escapechar=`,
  fancyvrb=false,%
  tabsize=2,%
  breaklines=true,
  breakatwhitespace=true,%
  captionpos=b,%
  frame=single,%
  framerule=0.2pt,%
  framesep=1pt,%
  showstringspaces=false,%
  columns=fixed%,
  \lst@ifdisplaystyle\scriptsize\fi,%
  identifierstyle=,%
  keywords=\bfseries,%
  keywordstyle=\color[rgb]{0, 0.5, 0.5},
  escapeinside={(*}{*)},
  literate={~}{{$\sim$}}1 {==}{{=\,=}}2,
  alsoother={$},
  alsoletter={.<-},%
  otherkeywords={!,!=,~,$,*,\&,\%/\%,\%*\%,\%\%,<-,<<-,/},
  numbers=left,
  %numberblanklines=false,%
  stepnumber=5,
  firstnumber=1,
  numberstyle={\tiny}
}

\renewenvironment{Schunk}{}{}
\renewenvironment{Sinput}{}{}
\let\Sinput\relax
\let\Scode\relax
\let\Soutput\relax
\lstnewenvironment{Sinput}{\lstset{style=Rinput}}{}
\lstnewenvironment{Scode}{\lstset{style=Rinput}}{}
\lstnewenvironment{Soutput}{\lstset{style=Routput}}{}
%%end paste in from guidePreambleSweavel.tex


\lstset{tabsize=2, breaklines=true, style=Rinput, breakatwhitespace=true}

\fvset{listparameters={\setlength{\topsep}{0em}}}

\usepackage{xcolor}
\definecolor{light-gray}{gray}{0.90}
\usepackage{realboxes}
\providecommand*{\code}[1]{\texttt{#1}}
\renewcommand{\code}[1]{%
\Colorbox{light-gray}{#1}%
}%
%% end of paste

\usepackage[natbibapa]{apacite}

\definecolor{darkblue}{HTML}{1e2277}

%would be in beamerthemekucrmda%
\mode<presentation>
\definecolor{kublue}{RGB}{0,81,186}
\usefonttheme{professionalfonts}
\useoutertheme{infolines}
\useinnertheme{rounded}
%disable rounded for alert and example boxes%
\setbeamertemplate{blocks}[default]
\usecolortheme{whale}
\usecolortheme{orchid}
\setbeamercolor{structure}{bg=kublue,fg=kublue!90!black}
%\setbeamercolor{structure}{fg=kublue}
\setbeamercolor{frametitle}{bg=kublue}
\setbeamercolor{section in toc}{fg=kublue!40!black}

\setbeamertemplate{frametitle continuation}[from second]
\renewcommand\insertcontinuationtext{...}
\beamertemplatenavigationsymbolsempty
%end of beamerthemekucrmda%

%If you want bigger margins, try this:
\setbeamersize{text margin left=05mm,text margin right=10mm} 
\hypersetup{colorlinks,allcolors=.,urlcolor=darkblue}
%Following seems to have no effect now
%\usepackage{handoutWithNotes}
%\pgfpagesuselayout{3 on 1 with notes}[letterpaper, border shrink=5mm]

\titlegraphic{\includegraphics[width=6cm]{theme/logo}}
\logo{\includegraphics[width=5mm]{theme/logomini}}
\DeclareUnicodeCharacter{2212}{-}
\end_preamble
\options aspectratio=1609
\use_default_options false
\begin_modules
logicalmkup
sweave
natbibapa
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding utf8
\fontencoding global
\font_roman "lmodern" "default"
\font_sans "lmss" "default"
\font_typewriter "lmtt" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures false
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 10
\spacing single
\use_hyperref false
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks true
\pdf_pdfborder false
\pdf_colorlinks true
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine natbib
\cite_engine_type authoryear
\biblio_style \use_bibtopic false
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\use_minted 0
\branch R
\selected 1
\filename_suffix 0
\color #faf0e6
\end_branch
\branch semboot
\selected 1
\filename_suffix 0
\color #d6fbd6
\end_branch
\branch cfalvm
\selected 1
\filename_suffix 0
\color #d6fbd6
\end_branch
\branch tpowsim
\selected 1
\filename_suffix 0
\color #faf0e6
\end_branch
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation skip
\defskip smallskip
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

%following is LyX shortcut 
\backslash
vb for bold upright math for matrices
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\vb}[1]{\bm{\mathrm{#1}}}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Branch R
inverted 0
status open

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

% tmpout directory must exist first
\end_layout

\begin_layout Plain Layout

<<tmpout, echo=FALSE, include=FALSE, results=hide>>=
\end_layout

\begin_layout Plain Layout

tdir <- "tmpout"
\end_layout

\begin_layout Plain Layout

if(!dir.exists(tdir)) dir.create(tdir, showWarnings=FALSE)
\end_layout

\begin_layout Plain Layout

@
\end_layout

\begin_layout Plain Layout

% In document Latex options:
\end_layout

\begin_layout Plain Layout


\backslash
fvset{listparameters={
\backslash
setlength{
\backslash
topsep}{0em}}}
\end_layout

\begin_layout Plain Layout


\backslash
SweaveOpts{prefix.string=tmpout/t,split=T,ae=F,height=4.5,width=7}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<Roptions, include=F, results=hide>>=
\end_layout

\begin_layout Plain Layout

opts.orig <- options()
\end_layout

\begin_layout Plain Layout

options(width=100, prompt = " ", continue = "  ")
\end_layout

\begin_layout Plain Layout

options(useFancyQuotes = FALSE)
\end_layout

\begin_layout Plain Layout

set.seed(12345)
\end_layout

\begin_layout Plain Layout

par.orig <- par(no.readonly = TRUE) 
\end_layout

\begin_layout Plain Layout

pjmar <- c(4.1, 4.1, 1.5, 2.1)
\end_layout

\begin_layout Plain Layout

options(SweaveHooks=list(fig=function() par(mar=pjmar, ps=12, xpd=F)))
\end_layout

\begin_layout Plain Layout

pdf.options(onefile=F,family="Times",pointsize=12)
\end_layout

\begin_layout Plain Layout

if(!file.exists("theme")) file.symlink("../../../../template/theme", "theme")
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Title
Power Analysis 
\begin_inset Argument 1
status open

\begin_layout Plain Layout
power
\end_layout

\end_inset


\end_layout

\begin_layout Author
Terrence Jorgensen, Ben Kite, Paul Johnson
\begin_inset Flex InstituteMark
status open

\begin_layout Plain Layout
1
\end_layout

\end_inset


\begin_inset Argument 1
status open

\begin_layout Plain Layout
JKJ
\end_layout

\end_inset


\end_layout

\begin_layout Institute
\begin_inset Flex InstituteMark
status collapsed

\begin_layout Plain Layout
1
\end_layout

\end_inset

Center for Research Methods and Data Analysis 
\begin_inset Argument 1
status open

\begin_layout Plain Layout
CRMDA
\end_layout

\end_inset


\end_layout

\begin_layout Date
2018
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
The following causes the table of contents to be shown at the beginning
 of every subsection.
 Delete this, if you do not want it.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
AtBeginSection[]{
\end_layout

\begin_layout Plain Layout

  
\backslash
frame<beamer>{ 
\end_layout

\begin_layout Plain Layout

    
\backslash
frametitle{Outline}
\end_layout

\begin_layout Plain Layout

    
\backslash
tableofcontents[currentsection] 
\end_layout

\begin_layout Plain Layout

  }
\end_layout

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}[containsverbatim, allowframebreaks]
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{Outline}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{Recall Hypothesis Testing?}
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
This is mostly about using R 
\begin_inset CommandInset citation
LatexCommand citep
key "RCore"
literal "true"

\end_inset

 for power analysis
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Section
Power Framework
\end_layout

\begin_layout Subsection
Hypothesis Testing
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{Recall Hypothesis Testing?}
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Null Hypothesis Significance Testing (NHST) is a common application in social
 science
\end_layout

\begin_layout Itemize
Frame research hypothesis as 
\end_layout

\begin_deeper
\begin_layout Itemize
a 
\begin_inset Quotes eld
\end_inset

null
\begin_inset Quotes erd
\end_inset

 hypothesis (
\begin_inset Formula $H_{0}$
\end_inset

) that is assumed true, and is to be rejected, in favor of
\end_layout

\begin_layout Itemize
the “alternative” hypothesis (
\begin_inset Formula $H_{1}$
\end_inset

) 
\end_layout

\end_deeper
\begin_layout Itemize
Design study (collect data) to test 
\begin_inset Formula $H_{0}$
\end_inset


\end_layout

\begin_layout Itemize
Logic: Reject 
\begin_inset Formula $H_{0}$
\end_inset

 if data results are unexpected if 
\begin_inset Formula $H_{0}$
\end_inset

 were true
\end_layout

\begin_layout Itemize
If you fail to reject 
\begin_inset Formula $H_{0}$
\end_inset

, that means 
\begin_inset Formula $H_{0}$
\end_inset

 is a plausible explanation for the observed data
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{Estimate of $
\backslash
theta$ is way out there.
 Or not}
\end_layout

\end_inset


\end_layout

\begin_layout ColumnsTopAligned

\end_layout

\begin_deeper
\begin_layout Column
6cm
\end_layout

\begin_layout Standard
Exciting! New! Different
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
includegraphics[width=6cm]{importfigs/t-idea20.pdf}
\end_layout

\end_inset


\end_layout

\begin_layout Column
6cm
\end_layout

\begin_layout Standard
Just what we expected all along
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
includegraphics[width=6cm]{importfigs/t-idea30.pdf}
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{Examples of $H_{0}$}
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Theory
\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Formula $ElectricityDemand=\beta_{0}+\beta_{1}Wealth+ε$
\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
Hypothesis testing
\end_layout

\begin_deeper
\begin_layout Itemize
Null Hypothesis: Effect of wealth on electricity demand is 7
\begin_inset Formula 
\[
H_{0}:\beta_{1}=7
\]

\end_inset


\end_layout

\begin_layout Itemize
The estimate from data is 
\begin_inset Formula $\hat{\beta}_{1}=10$
\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
Question: Is 10 far enough from 7 for 
\begin_inset Formula $H_{0}$
\end_inset

 to be rejected?
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}[allowframebreaks, containsverbatim]
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{"nil" versus "null" hypothesis tests}
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Previous example had meaningful null based on experience
\end_layout

\begin_layout Itemize
Often we assert simply the null value is 0, as if to say 
\begin_inset Quotes eld
\end_inset

variable X does not matter
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Itemize
That 
\begin_inset Quotes eld
\end_inset

nil
\begin_inset Quotes erd
\end_inset

 hypothesis test is useful when comparing groups
\end_layout

\begin_layout Itemize
Example: we build a model in which the expected value of depression in humans
 is 
\begin_inset Formula $\mu$
\end_inset

.
\end_layout

\begin_deeper
\begin_layout Itemize
Another person says our model is incorrect because it ignored gender differences.
 They suggest instead there should be two parameters, 
\begin_inset Formula $\mu_{men}$
\end_inset

 and 
\begin_inset Formula $\mu_{women}$
\end_inset

.
 
\end_layout

\begin_layout Itemize
To decide, we create a new parameter, 
\begin_inset Formula $\mu_{diff}=\mu_{men}-\mu_{women}$
\end_inset

 and try to estimate it.
\end_layout

\begin_layout Itemize
Set the null, 
\begin_inset Formula $H_{0}:\mu_{diff}=0$
\end_inset


\end_layout

\begin_layout Itemize
Suppose the estimate is 
\begin_inset Formula $\hat{\mu}_{diff}=-5$
\end_inset


\end_layout

\begin_layout Itemize
Is the observed difference big enough to convince us that 
\begin_inset Formula $H_{0}$
\end_inset

 is untenable?
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{Type I and Type II error}
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Type I error: the null is true, but our procedure rejects it
\end_layout

\begin_layout Itemize
Type II error: the null is false, but our procedure does not reject it
\end_layout

\begin_layout Itemize
Many statistical procedures are based on the idea that we accept a certain
 level of risk–
\begin_inset Formula $\alpha$
\end_inset

– in making a Type I error, we will incorrectly reject the null hypothesis
\end_layout

\begin_layout Itemize
The acceptable risk, 
\begin_inset Formula $\alpha$
\end_inset

, depends on field of research and context.
 
\end_layout

\begin_deeper
\begin_layout Itemize
Social science, often 
\begin_inset Formula $0.05$
\end_inset


\end_layout

\begin_layout Itemize
Medical science, sometimes 
\begin_inset Formula $0.01$
\end_inset

 or 
\begin_inset Formula $0.001$
\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{What is Statistical Power?}
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
The chance of making a Type II error is often called 
\begin_inset Formula $\beta$
\end_inset

.
 Unlike 
\begin_inset Formula $\alpha$
\end_inset

, it is not a parameter we set, so much as problem we incur.
\end_layout

\begin_layout Description
Power The probability of rejecting the null, if it is FALSE 
\end_layout

\begin_deeper
\begin_layout Itemize
power is 
\begin_inset Formula $1-\beta$
\end_inset

 AKA (1 – chance of Type II error)
\end_layout

\end_deeper
\begin_layout Itemize
Power concept only makes sense in the context of NHST 
\end_layout

\begin_layout Itemize
Should power analysis conduct before data collection (avoid post hoc) 
\end_layout

\begin_layout Itemize
Power is affected by 4 factors
\end_layout

\begin_deeper
\begin_layout Itemize
Rejection criterion (
\begin_inset Formula $\alpha$
\end_inset

 level)
\end_layout

\begin_layout Itemize
Sample size (
\begin_inset Formula $N$
\end_inset

)
\end_layout

\begin_layout Itemize
Variability anticipated from one sample to another
\end_layout

\begin_layout Itemize
Effect size (the degree to which 
\begin_inset Formula $H_{0}$
\end_inset

 is false)
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Subsection*
Visualization
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}[allowframebreaks, containsverbatim]
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{Rejection Rates}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Power and Type I concepts are based on the idea of a sampling distribution
 
\begin_inset Quotes eld
\end_inset

under the null hypothesis
\begin_inset Quotes erd
\end_inset

.
\end_layout

\begin_layout Itemize
Type I error rates refer to the probability of rejecting a null hypothesis.
 
\end_layout

\begin_layout Itemize
When the null is FALSE, you'd like to reject it as often as possible (have
 high power).
\end_layout

\begin_layout Itemize
The following R code will show how you can visualize that.
\end_layout

\begin_deeper
\begin_layout Standard
adjust N, SD, alpha, and ES (one at a time) to see how they affect power
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}[allowframebreaks, containsverbatim]
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{Rejection Rates}
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Plot the sampling distribution under the null hypothesis
\end_layout

\begin_layout Itemize
This is based on assumption we've scaled the estimator so that its true
 standard deviation is 1.0 and true center point is 0
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<pow100, fig=T>>=
\end_layout

\begin_layout Plain Layout

x.null <- seq(-4, 4, .1)
\end_layout

\begin_layout Plain Layout

dx.null <- dnorm(x.null, m = 0, s = 1)
\end_layout

\begin_layout Plain Layout

plot(x.null, dx.null, type = "l", lwd = 2, xlim = c(-4, 8), yaxt = "n",
\end_layout

\begin_layout Plain Layout

xlab = "Effect Size (e.g., Mean-Difference between Groups)", ylab = "")
\end_layout

\begin_layout Plain Layout

## If abs(z) > 1.96, reject the null at alpha = .05
\end_layout

\begin_layout Plain Layout

abline(v = qnorm(c(.025, .975)), lwd = 2, lty = "dashed")
\end_layout

\begin_layout Plain Layout

## Type I errors occur for observations drawn outside the dashed lines
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}[allowframebreaks, containsverbatim]
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{Discussion}
\end_layout

\end_inset


\end_layout

\begin_layout ColumnsTopAligned

\end_layout

\begin_deeper
\begin_layout Column
6cm
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
includegraphics[width=6cm]{tmpout/t-pow100}
\end_layout

\end_inset


\end_layout

\begin_layout Column
6cm
\end_layout

\begin_layout Itemize
Type I errors occur for estimates that are outside the dashed lines
\end_layout

\begin_layout Itemize
Power is not a meaningful concept when discussing the sampling distribution
 under the null
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}[allowframebreaks, containsverbatim]
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{Imagine an Alternate Reality}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<pow120, fig=T>>=
\end_layout

\begin_layout Plain Layout

<<pow100>>
\end_layout

\begin_layout Plain Layout

x.8 <- x.null + 0.80
\end_layout

\begin_layout Plain Layout

dx.8 <- dnorm(x.8, m = 0.80)
\end_layout

\begin_layout Plain Layout

lines(x.8, dx.8, lwd = 2, col = "red")
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}[allowframebreaks, containsverbatim]
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{Discussion}
\end_layout

\end_inset


\end_layout

\begin_layout ColumnsTopAligned

\end_layout

\begin_deeper
\begin_layout Column
6cm
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
includegraphics[width=6cm]{tmpout/t-pow120}
\end_layout

\end_inset


\end_layout

\begin_layout Column
6cm
\end_layout

\begin_layout Itemize
The red line is the 
\begin_inset Quotes eld
\end_inset

true
\begin_inset Quotes erd
\end_inset

 sampling distribution, as it occurs under a hypothesized alternative
\end_layout

\begin_layout Itemize
The red sampling distribution overlaps with the black (null) distribution
 to a considerable extent.
 Under the red, the null is rejected more often, but it is not rejected
 with extremely high probability.
\end_layout

\begin_layout Itemize
Most would say this is an 
\begin_inset Quotes eld
\end_inset

under-powered study
\begin_inset Quotes erd
\end_inset

.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}[allowframebreaks, containsverbatim]
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{In a World Where $
\backslash
ldots$}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Effect sizes are much larger (Gigantic by Cohen's standards)
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<pow140, fig=T>>=
\end_layout

\begin_layout Plain Layout

<<pow100>>
\end_layout

\begin_layout Plain Layout

x.25 <- c(x.null + 2.5)
\end_layout

\begin_layout Plain Layout

dx.25 <- dnorm(x.8, m = 2.5, s = 1)
\end_layout

\begin_layout Plain Layout

lines(x.25, dx.25, lwd = 2, col = "red")
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}[allowframebreaks, containsverbatim]
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{Discussion}
\end_layout

\end_inset


\end_layout

\begin_layout ColumnsTopAligned

\end_layout

\begin_deeper
\begin_layout Column
6cm
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
includegraphics[width=6cm]{tmpout/t-pow140}
\end_layout

\end_inset


\end_layout

\begin_layout Column
6cm
\end_layout

\begin_layout Itemize
If we assume the true effect is massive, then the power analysis will say
 we have great power.
\end_layout

\begin_layout Itemize
Critics will say we are proposing a ridiculously huge difference between
 groups
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}[allowframebreaks, containsverbatim]
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{In a World Where $
\backslash
ldots$}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Standard error of sampling distribution is smaller
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<pow160, fig=T>>=
\end_layout

\begin_layout Plain Layout

x.null <- seq(-4, 4, .1)
\end_layout

\begin_layout Plain Layout

dx.null <- dnorm(x.null, m = 0, s = 0.5)
\end_layout

\begin_layout Plain Layout

plot(x.null, dx.null, type = "l", lwd = 2, xlim = c(-4, 8), yaxt = "n",
\end_layout

\begin_layout Plain Layout

xlab = "Effect Size (e.g., Mean-Difference between Groups)", ylab = "")
\end_layout

\begin_layout Plain Layout

## If abs(z) > 1.96, reject the null at alpha = .05
\end_layout

\begin_layout Plain Layout

abline(v = qnorm(c(.025, .975), m = 0, s = 0.5), lwd = 2, lty = "dashed")
\end_layout

\begin_layout Plain Layout

## Type I errors occur for observations drawn outside the dashed lin
\end_layout

\begin_layout Plain Layout

x.1 <- c(x.null + 1)
\end_layout

\begin_layout Plain Layout

dx.1 <- dnorm(x.8, m = 1, s = 0.5)
\end_layout

\begin_layout Plain Layout

lines(x.1, dx.1, lwd = 2, col = "red")
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}[allowframebreaks, containsverbatim]
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{Discussion}
\end_layout

\end_inset


\end_layout

\begin_layout ColumnsTopAligned

\end_layout

\begin_deeper
\begin_layout Column
6cm
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
includegraphics[width=6cm]{tmpout/t-pow160}
\end_layout

\end_inset


\end_layout

\begin_layout Column
6cm
\end_layout

\begin_layout Itemize
Rather than supposing that the effect size gets bigger and bigger (which
 is frowned upon)
\end_layout

\begin_layout Itemize
Best idea is to suppose the standard error can be 
\begin_inset Quotes eld
\end_inset

shrunken
\begin_inset Quotes erd
\end_inset

 by using larger and larger sample sizes.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Motivation
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{Motivation for Power Analysis}
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Required by funding agencies that award research proposals
\end_layout

\begin_deeper
\begin_layout Itemize
How many cases are required to reject your 
\begin_inset Formula $H_{0}$
\end_inset

?
\end_layout

\begin_layout Itemize
Funding agencies (and dissertation advisors) want to make sure we aren’t
 wasting time and money 
\end_layout

\end_deeper
\begin_layout Itemize
Think backwards
\end_layout

\begin_deeper
\begin_layout Itemize
Imagine a completed study, with data
\end_layout

\begin_layout Itemize
MUST write down the actual model to be estimated
\end_layout

\begin_layout Itemize
With “made up data” of size N, using carefully chosen population parameters,
 how often is a “significant” effect detected? 
\end_layout

\begin_layout Itemize
If not, how large must N be to detect the effect at least as often as a
 minimum threshold?
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{Real-Life Research Example}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Researcher collects data on N = 10 people to find out whether tobacco causes
 cancer
\end_layout

\begin_layout Itemize
Statistical procedure says there’s no relationship, so we can’t reject 
\begin_inset Formula $H_{0}$
\end_inset

 of no relationship
\end_layout

\begin_layout Itemize
Suppose the effect of tobacco on cancer risk is actually present, but we
 missed it by not collecting enough data (Type II error)
\end_layout

\begin_layout Itemize
80% is a customary threshold for “enough” power
\end_layout

\begin_layout Itemize
We should design experiments so 
\begin_inset Formula $power\geq0.8$
\end_inset


\end_layout

\begin_layout Itemize
You wish 
\end_layout

\begin_deeper
\begin_layout Itemize
error variance would be small
\end_layout

\begin_layout Itemize
Effect must be “large” 
\end_layout

\end_deeper
\begin_layout Itemize
You may need to dial up the sample size otherwise.
\end_layout

\begin_deeper
\begin_layout Itemize
A bigger sample almost always increases chances of finding a “significant”
 result (i.e., of rejecting 
\begin_inset Formula $H_{0}$
\end_inset

)
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Effect Sizes
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{Effect Sizes}
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Quotes eld
\end_inset

Effect Size
\begin_inset Quotes erd
\end_inset

 is a term coming from education and psychological research.
 It is motivated by the desire to reduce limitations of 
\begin_inset Quotes eld
\end_inset

apples and oranges
\begin_inset Quotes erd
\end_inset

 comparisons
\end_layout

\begin_layout Itemize
\begin_inset Quotes eld
\end_inset

Raw Effect Sizes
\begin_inset Quotes erd
\end_inset

 are the parameter estimate minus the null hypothesized value 
\end_layout

\begin_deeper
\begin_layout Itemize
Regression slopes (
\begin_inset Formula $\hat{\beta}$
\end_inset

 − 
\begin_inset Formula $\beta_{null}$
\end_inset

 ) 
\end_layout

\begin_layout Itemize
Mean-differences between groups (
\begin_inset Formula $\hat{u}_{group\,1}-\hat{\mu}_{group\,2}$
\end_inset

)
\end_layout

\end_deeper
\begin_layout Itemize
Attempts to 
\begin_inset Quotes eld
\end_inset

standardize
\begin_inset Quotes erd
\end_inset

 effect sizes across studies usually rely on standard errors, e.g., 
\end_layout

\begin_deeper
\begin_layout Itemize
Divide difference by SE for a t statistic
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{Effect Sizes}
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Effect Size = magnitude of difference between a parameter estimate and its
 
\begin_inset Formula $H_{0}$
\end_inset

 value, eg 
\begin_inset Formula $\hat{\mu}-\mu$
\end_inset

 
\end_layout

\begin_layout Itemize
APA and some funding agencies suggest/require “standardized” effect sizes
\end_layout

\begin_deeper
\begin_layout Itemize
Seeking a number that is generic across contexts
\end_layout

\begin_layout Itemize
Supposed to represent “practical” significance, but effects in units of
 SD or proportions are not always intuitive or useful
\end_layout

\end_deeper
\begin_layout Itemize
Cohen (1988) pioneered the most frequently used criteria for describing
 effect sizes and estimating power among social scientists
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{How do Effect Sizes Matter in Power Analysis?}
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Researchers are pressured to change the way they think about the eventual
 analysis
\end_layout

\begin_layout Itemize
Rather than saying 
\begin_inset Quotes eld
\end_inset

the difference between people from the North and South is 7 units
\begin_inset Quotes erd
\end_inset

 
\end_layout

\begin_deeper
\begin_layout Itemize
they are expected to say 
\begin_inset Quotes eld
\end_inset

in standardized effect size units, the difference between people from the
 North and South is 0.4 units
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Itemize
The power calculation has to be scaled into the standardized effect sizes
\end_layout

\end_deeper
\begin_layout Itemize
Presumably, by putting expected differences into terms of standardized effect
 sizes, a project reviewer can look at the anticipated difference and say
 
\begin_inset Quotes eld
\end_inset

that is unrealistically large
\begin_inset Quotes erd
\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Section
Cookbook answers
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{G Power}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
G*Power (
\begin_inset Flex URL
status open

\begin_layout Plain Layout

http://www.gpower.hhu.de/en.html
\end_layout

\end_inset

)
\end_layout

\begin_layout Itemize
Cookbook works with regression, correlation, t test, ANOVA, ANCOVA, MANOVA,
 MANCOVA
\end_layout

\begin_layout Itemize
Some generalized linear models (Poisson or logistic regression)
\end_layout

\begin_layout Itemize
Contingency tables (
\begin_inset Formula $\chi^{2}$
\end_inset

, McNemar’s test)
\end_layout

\begin_layout Itemize
Proportion tests
\end_layout

\begin_layout Itemize
The user’s manual on the website is easy to read (pictures and easy instructions
)
\end_layout

\begin_layout Itemize
But...
 G*Power only covers fairly simple cases.
 
\end_layout

\begin_deeper
\begin_layout Itemize
"Standardized" effect sizes aren't intuitive.
 
\end_layout

\begin_layout Itemize
When you need to know the power simultaneously for several tests/parameters
 in a single model, then Monte Carlo methods become necessary where analytical
 methods break down.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}[allowframebreaks]
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{Multilevel Models}
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
PINT (
\begin_inset Flex URL
status open

\begin_layout Plain Layout

http://www.stats.ox.ac.uk/~snijders/multilevel.htm
\backslash
#progPINT
\end_layout

\end_inset

 )
\end_layout

\begin_deeper
\begin_layout Itemize
Uses analytical approximation, 2-level models only
\end_layout

\begin_layout Itemize
Faster than a simulation, perhaps more analytically meaningful
\end_layout

\end_deeper
\begin_layout Itemize
MLPowSim ( 
\begin_inset Flex URL
status open

\begin_layout Plain Layout

http://www.bristol.ac.uk/cmm/software/mlpowsim
\end_layout

\end_inset

 )
\end_layout

\begin_deeper
\begin_layout Itemize
Writes an R file with which one can do an MC Power simulation, after
\end_layout

\begin_layout Itemize
User runs a program-builder program that quizzes the user about 
\end_layout

\begin_deeper
\begin_layout Itemize
design, predictors, parameters
\end_layout

\end_deeper
\begin_layout Itemize
Has been 
\begin_inset Quotes eld
\end_inset

beta software
\begin_inset Quotes erd
\end_inset

 for 7 years, will probably never be 
\begin_inset Quotes eld
\end_inset

done
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Itemize
Only available for Windows
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{WebPower}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
WebPower ( 
\begin_inset Flex URL
status open

\begin_layout Plain Layout

http://webpower.psychstat.org/wiki
\end_layout

\end_inset

/ ) 
\end_layout

\begin_layout Itemize
Correlation, regression
\end_layout

\begin_layout Itemize
Proportion/Mean differences
\end_layout

\begin_layout Itemize
Mediation
\end_layout

\begin_layout Itemize
Multilevel and Longitudinal modeling
\end_layout

\begin_layout Itemize
Structural equation modeling
\end_layout

\begin_layout Itemize
Fairly new, may have bugs
\end_layout

\begin_layout Standard
Zhang, Z., & Yuan, K.-H.
 (2018).
 
\emph on
Practical Statistical Power Analysis Using Webpower and R
\emph default
 (Eds).
 Granger, IN: ISDSA Press.
 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{Mplus Software Suite}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
For SEMs (and more), see CRMDA Guide 12: 
\emph on
Monte Carlo Simulation in Mplus 
\begin_inset CommandInset href
LatexCommand href
name "Monte Carlo Simulation in Mplus"
target "https://crmda.ku.edu/guide-12-Mplus_monte_carlo"
literal "false"

\end_inset


\emph default
 (other guides 
\begin_inset Flex URL
status open

\begin_layout Plain Layout

http://crmda.ku.edu/guides-index
\end_layout

\end_inset

)
\end_layout

\begin_layout Itemize
Mplus is primarily SEM software (not free), but it can also be used for
 anything that can be framed as a
\end_layout

\begin_deeper
\begin_layout Itemize
Linear model (t test, ANOVA, regression)
\end_layout

\begin_layout Itemize
Generalized linear model (Poisson or logistic regression)
\end_layout

\begin_layout Itemize
Multilevel / mixed-effects model
\end_layout

\end_deeper
\begin_layout Itemize
Just need to know how to write model in Mplus syntax
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}[containsverbatim, allowframebreaks]
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{R package "pwr"}
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
As usual, 
\end_layout

\begin_deeper
\begin_layout Itemize
if you don't have pwr, install with 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
install.packages(
\begin_inset Quotes eld
\end_inset

pwr
\begin_inset Quotes erd
\end_inset

)
\end_layout

\end_inset

.
\end_layout

\begin_layout Itemize
Review the help page with 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
help(package = pwr)
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<pwr100>>=
\end_layout

\begin_layout Plain Layout

library(pwr)
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}[containsverbatim, allowframebreaks]
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{Normative standards in pwr}
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Cohen offered opinions about realistic norms for small, medium and large
 effects in various kinds of statistical models.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
def
\backslash
Rsize{
\backslash
scriptsize}
\end_layout

\begin_layout Plain Layout

<<pwr200>>=
\end_layout

\begin_layout Plain Layout

cohen.ES(test = "t", size = "large")    # Cohen's D
\end_layout

\begin_layout Plain Layout

cohen.ES(test = "t", size = "medium")
\end_layout

\begin_layout Plain Layout

cohen.ES(test = "t", size = "small")
\end_layout

\begin_layout Plain Layout

cohen.ES(test = "r", size = "large")    # Pearson's r (correlation)
\end_layout

\begin_layout Plain Layout

cohen.ES(test = "r", size = "medium")
\end_layout

\begin_layout Plain Layout

cohen.ES(test = "r", size = "small")
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

cohen.ES(test = "anov", size = "small") # Cohen's f_squared
\end_layout

\begin_layout Plain Layout

cohen.ES(test = "f2", size = "small")   # Cohen's f_squared
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}[containsverbatim, allowframebreaks]
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{Approximate Power Guesses for Simple Stats}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
def
\backslash
Rsize{
\backslash
scriptsize}
\end_layout

\begin_layout Plain Layout

<<pwr300>>=
\end_layout

\begin_layout Plain Layout

## Find power for a given sample size, effect size, and alpha level
\end_layout

\begin_layout Plain Layout

pwr.r.test(n = 30, r = .1, sig.level = .05)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

## A priori power analysis: Find sample size required for a given
\end_layout

\begin_layout Plain Layout

## level of power, alpha, and effect size
\end_layout

\begin_layout Plain Layout

pwr.r.test(power = .80, r = .1, sig.level = .05)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

## Do the same with Cohen's D for a t test
\end_layout

\begin_layout Plain Layout

pwr.t.test(n = 30, d = .2, sig.level = .05)
\end_layout

\begin_layout Plain Layout

pwr.t.test(power = .80, d = .2, sig.level = .05)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

## repeat without the requirement for equal group sizes
\end_layout

\begin_layout Plain Layout

pwr.t2n.test(n1 = 20, n2 = 12, d = .2, sig.level = .05)
\end_layout

\begin_layout Plain Layout

pwr.t2n.test(power = .8, n1 = 40, d = .5, sig.level = .05)
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Section
Monte Carlo Power
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{Monte Carlo Power Analysis}
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
A Monte Carlo study where:
\end_layout

\begin_deeper
\begin_layout Itemize
The outcome of interest is statistical power
\end_layout

\begin_layout Itemize
The main manipulated factor is N
\end_layout

\end_deeper
\begin_layout Itemize
Useful because analytical methods only cover simple cases
\end_layout

\begin_deeper
\begin_layout Itemize
Power = the proportion of samples in a condition for which 
\begin_inset Formula $H_{0}$
\end_inset

 was rejected
\end_layout

\end_deeper
\begin_layout Itemize
Can manipulate other factors
\end_layout

\begin_deeper
\begin_layout Itemize
Effect size, alpha, variability, missing data, etc.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Worked Example 1
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}[allowframebreaks,containsverbatim]
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{Explore the Two-Group Simulation}
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
In the Monte Carlo lecture, we developed a series of functions that can
 estimate the 
\begin_inset Formula $H_{0}$
\end_inset

 rejection rates for a problem with normally distributed data in which two
 groups are observed.
\end_layout

\begin_layout Itemize
We developed an idiom to describe the group
\end_layout

\begin_deeper
\begin_layout Itemize
Sample size: N
\end_layout

\begin_layout Itemize
Mean: M
\end_layout

\begin_layout Itemize
Standard Deviation: SD
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}[allowframebreaks,containsverbatim]
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{tPowerSim}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Here is how we might fit the various functions together more tightly
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
def
\backslash
Rsize{
\backslash
scriptsize}
\end_layout

\begin_layout Plain Layout

<<>>=
\end_layout

\begin_layout Plain Layout

##' Monte Carlo simulation for 2 group t test
\end_layout

\begin_layout Plain Layout

##' @param conds = a conditions data frame
\end_layout

\begin_layout Plain Layout

##' @param var.equal: should the t.test use the equal variance 
\end_layout

\begin_layout Plain Layout

##' assumption or the Welch corrected calculation (if FALSE).
\end_layout

\begin_layout Plain Layout

##' Note default TRUE is different from R base.
\end_layout

\begin_layout Plain Layout

##' @return a matrix summarizing rejection rates
\end_layout

\begin_layout Plain Layout

tPowerSim <- function(conds, var.equal = TRUE){
\end_layout

\begin_layout Plain Layout

    ## Creates data by parsing N, M and SD strings
\end_layout

\begin_layout Plain Layout

    getTdata <- function(rep, N, M, SD) {
\end_layout

\begin_layout Plain Layout

        Nvec <- as.numeric(unlist(strsplit(N, ":")))
\end_layout

\begin_layout Plain Layout

        Mvec <- as.numeric(unlist(strsplit(M, ":")))
\end_layout

\begin_layout Plain Layout

        SDvec <- as.numeric(unlist(strsplit(SD, ":")))
\end_layout

\begin_layout Plain Layout

        
\end_layout

\begin_layout Plain Layout

        dat <- data.frame(first = c(rep(0, times = Nvec[1]),
\end_layout

\begin_layout Plain Layout

                                    rep(1, times = Nvec[2])))
\end_layout

\begin_layout Plain Layout

        dat$IQ <- rnorm(sum(Nvec), m = Mvec[(dat$first + 1)], 
\end_layout

\begin_layout Plain Layout

                        sd = SDvec[(dat$first + 1)])
\end_layout

\begin_layout Plain Layout

        dat$IQ <- round(dat$IQ)
\end_layout

\begin_layout Plain Layout

        attr(dat, "rep") <- rep
\end_layout

\begin_layout Plain Layout

        attr(dat, "parms") <- c(N = N, M = M, SD = SD)
\end_layout

\begin_layout Plain Layout

        dat
\end_layout

\begin_layout Plain Layout

    }
\end_layout

\begin_layout Plain Layout

    ## conducts T test, keeps only p value
\end_layout

\begin_layout Plain Layout

    conductTtest <- function (dframe, y = "IQ", x = "first", var.equal){
\end_layout

\begin_layout Plain Layout

        t.test(formula(paste(y, "~", x)),
\end_layout

\begin_layout Plain Layout

               data = dframe, var.equal = var.equal)$p.value
\end_layout

\begin_layout Plain Layout

    }
\end_layout

\begin_layout Plain Layout

    ## orchestrates the data pull, analysis, and summary
\end_layout

\begin_layout Plain Layout

    runOneSim <- function(rep, N, M, SD, var.equal){
\end_layout

\begin_layout Plain Layout

        dframe <- getTdata(rep, N = N, M = M, SD = SD)
\end_layout

\begin_layout Plain Layout

        reslt <- conductTtest(dframe, var.equal = var.equal)
\end_layout

\begin_layout Plain Layout

        parms <- attr(dframe, "parms")
\end_layout

\begin_layout Plain Layout

        dframe2 <- data.frame(rep = attr(dframe, "rep"), 
\end_layout

\begin_layout Plain Layout

                              pvalue = reslt,
\end_layout

\begin_layout Plain Layout

                              reject.05 = if (reslt <= 0.05) 1 else 0,
\end_layout

\begin_layout Plain Layout

                              reject.1 = if (reslt <= 0.10) 1 else 0,
\end_layout

\begin_layout Plain Layout

                              N = parms["N"], M = parms["M"], SD = parms["SD"])
\end_layout

\begin_layout Plain Layout

        dframe2
\end_layout

\begin_layout Plain Layout

    }
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    # Reads the condition matrix, runs one row from it
\end_layout

\begin_layout Plain Layout

    runOneCondition <- function(i, conds, var.equal){
\end_layout

\begin_layout Plain Layout

        x <- conds[i, ]
\end_layout

\begin_layout Plain Layout

        result.list <- lapply(1:x$nReps, runOneSim, 
\end_layout

\begin_layout Plain Layout

                              N = x$N, M = x$M, SD = x$SD, var.equal = var.equal)
\end_layout

\begin_layout Plain Layout

        do.call("rbind", result.list)
\end_layout

\begin_layout Plain Layout

    }
\end_layout

\begin_layout Plain Layout

     # Run all of the rows in the condition matrix
\end_layout

\begin_layout Plain Layout

    listofresults <- lapply(1:NROW(conds), runOneCondition, conds, var.equal
 = var.equal)
\end_layout

\begin_layout Plain Layout

    stackedResults <- do.call(rbind, listofresults)
\end_layout

\begin_layout Plain Layout

    output <- aggregate(stackedResults[, c("reject.05", "reject.1")],
\end_layout

\begin_layout Plain Layout

                        by = list(N = stackedResults$N, SD = stackedResults$SD,
 M = stackedResults$M),
\end_layout

\begin_layout Plain Layout

                        mean)
\end_layout

\begin_layout Plain Layout

    names(output) <- c("N", "SD", "M", "reject.05.mean", "reject.1.mean")
\end_layout

\begin_layout Plain Layout

    output
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}[allowframebreaks,containsverbatim]
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{Input is a conds matrix}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<>>=
\end_layout

\begin_layout Plain Layout

cond.N <- c("30:30", "40:20")
\end_layout

\begin_layout Plain Layout

cond.SD <- c("10:20", "15:15", "20:10")
\end_layout

\begin_layout Plain Layout

cond.M <- c("100:100") # for now, mean-difference = 0
\end_layout

\begin_layout Plain Layout

conds <- expand.grid(nReps = 1000, SD = cond.SD, N = cond.N, M = cond.M,
\end_layout

\begin_layout Plain Layout

                     stringsAsFactors = FALSE)
\end_layout

\begin_layout Plain Layout

head(conds)
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}[allowframebreaks,containsverbatim]
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{Example Run}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Branch tpowsim
inverted 0
status open

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<tpow400>>=
\end_layout

\begin_layout Plain Layout

tPowerSim(conds, var.equal = TRUE) 
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<tpow410>>=
\end_layout

\begin_layout Plain Layout

tPowerSim(conds, var.equal = FALSE)
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
input{tmpout/t-tpow400}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
input{tmpout/t-tpow410}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}[allowframebreaks,containsverbatim]
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{Experiment with That}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Branch tpowsim
inverted 0
status open

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
def
\backslash
Rsize{
\backslash
scriptsize}
\end_layout

\begin_layout Plain Layout

<<tpow500>>=
\end_layout

\begin_layout Plain Layout

## Play with tPowerSim.
  
\end_layout

\begin_layout Plain Layout

## I just "noodled" around a while
\end_layout

\begin_layout Plain Layout

## You can be systematic :)
\end_layout

\begin_layout Plain Layout

##
\end_layout

\begin_layout Plain Layout

## Power analysis is the study of data group sizes
\end_layout

\begin_layout Plain Layout

 
\end_layout

\begin_layout Plain Layout

cond.N <- c("30:30", "40:20", "100:100")
\end_layout

\begin_layout Plain Layout

cond.SD <- c("10:20", "15:15", "20:10")
\end_layout

\begin_layout Plain Layout

cond.M <- c("100:105")
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

conds <- expand.grid(nReps = 1000, SD = cond.SD, N = cond.N,
\end_layout

\begin_layout Plain Layout

            M = cond.M, stringsAsFactors = FALSE)
\end_layout

\begin_layout Plain Layout

tPowerSim(conds, var.equal = TRUE)
\end_layout

\begin_layout Plain Layout

tPowerSim(conds, var.equal = FALSE)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

cond.M <- c("100:106") 
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

conds <- expand.grid(nReps = 1000, SD = cond.SD, N = cond.N, 
\end_layout

\begin_layout Plain Layout

                     M = cond.M, stringsAsFactors = FALSE)
\end_layout

\begin_layout Plain Layout

tPowerSim(conds, var.equal = TRUE)
\end_layout

\begin_layout Plain Layout

tPowerSim(conds, var.equal = FALSE)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

cond.N <- c("100:100", "150:150", "150:100", "100:150")
\end_layout

\begin_layout Plain Layout

conds <- expand.grid(nReps = 1000, SD = cond.SD, N = cond.N, 
\end_layout

\begin_layout Plain Layout

                     M = cond.M, stringsAsFactors = FALSE)
\end_layout

\begin_layout Plain Layout

tPowerSim(conds, var.equal = TRUE)
\end_layout

\begin_layout Plain Layout

tPowerSim(conds, var.equal = FALSE)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

cond.M <- c("100:110")
\end_layout

\begin_layout Plain Layout

conds <- expand.grid(nReps = 1000, SD = cond.SD, N = cond.N,
\end_layout

\begin_layout Plain Layout

                     M = cond.M, stringsAsFactors = FALSE)
\end_layout

\begin_layout Plain Layout

tPowerSim(conds, var.equal = TRUE)
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
input{tmpout/t-tpow500}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Worked Example 2
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}[allowframebreaks,containsverbatim]
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{IQ study}
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
We are planning a study about parental IQ
\end_layout

\begin_layout Itemize
This is a study focused on a correlation, R, between the IQs of the parents
 (which are positively correlated).
\end_layout

\begin_layout Itemize
Cohen's guidelines say a 
\begin_inset Quotes eld
\end_inset

medium
\begin_inset Quotes erd
\end_inset

 correlation would be 0.30, so we will use that to manufacture data.
\end_layout

\begin_layout Itemize
We are going to manufacture data using a multivariate normal distribution
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}[allowframebreaks,containsverbatim]
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{Digression: Drawing MVN samples}
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
A vector of means 
\begin_inset Formula $\mu$
\end_inset

=
\begin_inset Quotes eld
\end_inset

mu
\begin_inset Quotes erd
\end_inset

 and a covariance matrix 
\begin_inset Formula $\Sigma$
\end_inset

=
\begin_inset Quotes erd
\end_inset

Sigma
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\vb x=\left[\begin{array}{c}
x_{1}\\
x_{2}\\
\vdots\\
x_{p}
\end{array}\right]\sim MVN(\vb{\mu},\vb{\Sigma})=MVN\left(\left[\begin{array}{c}
\mu_{1}\\
\mu_{2}\\
\vdots\\
\mu_{p}
\end{array}\right],\left[\begin{array}{cccc}
\sigma_{1}^{2} & \sigma_{12} &  & \sigma_{1p}\\
\sigma_{12} & \sigma_{2}^{2} &  & \sigma_{2p}\\
 &  & \ddots\\
\sigma_{1p} & \sigma_{2p} &  & \sigma_{p}^{2}
\end{array}\right]\right)
\]

\end_inset


\end_layout

\begin_layout Itemize
The one-variable formula for the probability density of the Normal distribution
\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Formula 
\[
f(x)=\frac{1}{\sqrt{2\pi}\sigma}\,e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^{2}}\,\mathrm{or\,}\,\frac{1}{(2\pi)^{1/2}\sigma}\,e^{-\frac{1}{2}\left(x-\mu\right)\sigma^{-1}\left(x-\mu\right)}
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
The multivariate one looks almost the same
\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Formula 
\[
f(\vb x)=\frac{1}{(2\pi)^{p/2}|\vb{\Sigma}|^{1/2}}e^{\frac{-1}{2}(\vb x-\vb{\mu})^{T}\vb{\Sigma}^{-1}(\vb x-\vb{\mu})}
\]

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $p$
\end_inset

 is the number of elements in 
\begin_inset Formula $\mu$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Itemize
We will create Sigma by specifying standard deviations and a correlation
 matrix, then we use this handy formula
\begin_inset Formula 
\[
SD.diagonal\times Corr.matrix\times SD.diagonal
\]

\end_inset


\end_layout

\begin_layout Standard

\size footnotesize
\begin_inset Formula 
\begin{eqnarray}
Sigma & = & \left[\begin{array}{ccccc}
\sigma_{x1} & 0 & 0 & 0 & 0\\
0 & \sigma_{x2} & 0 & 0 & 0\\
0 & 0 & \sigma_{x3} & 0 & 0\\
0 & 0 & 0 & \sigma_{x4} & 0\\
0 & 0 & 0 & 0 & \sigma_{x5}
\end{array}\right]\times\left[\begin{array}{ccccc}
1 & \rho_{12} & \rho_{13} & \ldots & \rho_{1p}\\
\rho_{21} & 1 & \rho_{23} &  & \rho_{2p}\\
\rho_{31} & \ddots & 1 &  & \rho_{3p}\\
\vdots & _{11} & \rho_{11} & \ddots\\
\rho_{p1} & \rho_{11} & \rho_{11} &  & 1
\end{array}\right]\nonumber \\
 &  & \times\left[\begin{array}{ccccc}
\sigma_{x1} & 0 & 0 & 0 & 0\\
0 & \sigma_{x2} & 0 & 0 & 0\\
0 & 0 & \sigma_{x3} & 0 & 0\\
0 & 0 & 0 & \sigma_{x4} & 0\\
0 & 0 & 0 & 0 & \sigma_{x5}
\end{array}\right]\label{eq:Cov1}
\end{eqnarray}

\end_inset


\end_layout

\begin_layout Itemize
The R implementation.
 We'll use 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
mvrnorm
\end_layout

\end_inset

 from the 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
rockchalk
\end_layout

\end_inset

 package, a slightly adjusted version of the one in MASS.
\end_layout

\begin_layout Itemize
rockchalk has convenience functions I created because I got tired of writing
 out matrix function calls
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<mvrnorm100>>=
\end_layout

\begin_layout Plain Layout

library(rockchalk)
\end_layout

\begin_layout Plain Layout

myR <- lazyCor(X = 0.3, d = 5)
\end_layout

\begin_layout Plain Layout

myR
\end_layout

\begin_layout Plain Layout

mySD <- c(0.5, 0.5, 0.5, 1.5, 1.5)
\end_layout

\begin_layout Plain Layout

myCov <- lazyCov(Rho = myR, Sd = mySD)
\end_layout

\begin_layout Plain Layout

myCov
\end_layout

\begin_layout Plain Layout

myMu <- c(1.1, 2.0, 1.1, -0.2, 0)
\end_layout

\begin_layout Plain Layout

## Draw one to see what that does
\end_layout

\begin_layout Plain Layout

set.seed(123123)
\end_layout

\begin_layout Plain Layout

mvrnorm(1, mu = myMu, myCov)
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Now create 1000 rows of that (5 columns)
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<mvrnorm150>>=
\end_layout

\begin_layout Plain Layout

N <- 1000
\end_layout

\begin_layout Plain Layout

X <- mvrnorm(N, mu = myMu, myCov)
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<mvrnorm200>>=
\end_layout

\begin_layout Plain Layout

## Check column means
\end_layout

\begin_layout Plain Layout

colMeans(X)
\end_layout

\begin_layout Plain Layout

## Check Pearson Correlations
\end_layout

\begin_layout Plain Layout

cor(X)
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}[allowframebreaks,containsverbatim]
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{Fiddle to find create IQ data generator}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
def
\backslash
Rsize{
\backslash
scriptsize}
\end_layout

\begin_layout Plain Layout

<<iq100>>=
\end_layout

\begin_layout Plain Layout

R <- 0.30 #"medium" in Cohen's opinion
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

## Start with a correlation matrix of predictors
\end_layout

\begin_layout Plain Layout

## If you do this the standard R way
\end_layout

\begin_layout Plain Layout

IQ.cor <- matrix(c(1, R, R, 1), nrow = 2, ncol = 2,
\end_layout

\begin_layout Plain Layout

                 dimnames = list(c("dadIQ", "momIQ"), 
\end_layout

\begin_layout Plain Layout

                              c("dadIQ", "momIQ")))
\end_layout

\begin_layout Plain Layout

IQ.cor 
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

## My equivalent method in rockchalk
\end_layout

\begin_layout Plain Layout

IQ.cor <- lazyCor(X = R, d = 2)
\end_layout

\begin_layout Plain Layout

IQ.cor
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

## these are the assumed means of momIQ and dadIQ
\end_layout

\begin_layout Plain Layout

IQ.M <- c(dadIQ = 100, momIQ = 100)
\end_layout

\begin_layout Plain Layout

## mvrnorm will take these as column names in the 
\end_layout

\begin_layout Plain Layout

## output.
 That's why those are named
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

## these are the standard devations of momIQ and dadIQ
\end_layout

\begin_layout Plain Layout

IQ.SD <- c(15, 15)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

## The diagonal matrix we need will be
\end_layout

\begin_layout Plain Layout

diag(IQ.SD) 
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

## Create the covariance matrix
\end_layout

\begin_layout Plain Layout

IQ.cov <- diag(IQ.SD) %*% IQ.cor %*% diag(IQ.SD)
\end_layout

\begin_layout Plain Layout

IQ.cov
\end_layout

\begin_layout Plain Layout

## Use R's builtin cov2cor to double-check thc
\end_layout

\begin_layout Plain Layout

## correlations
\end_layout

\begin_layout Plain Layout

cov2cor(IQ.cov)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

N <- 100
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

set.seed(123)
\end_layout

\begin_layout Plain Layout

dat <- mvrnorm(n = N, mu = IQ.M, Sigma = IQ.cov)
\end_layout

\begin_layout Plain Layout

dat <- as.data.frame(round(dat))
\end_layout

\begin_layout Plain Layout

head(dat)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

## Do observed means and correlations reflect 
\end_layout

\begin_layout Plain Layout

## the population parameters? Rounding is not too harmful
\end_layout

\begin_layout Plain Layout

colMeans(dat)
\end_layout

\begin_layout Plain Layout

cor(dat)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

## Now we will once again draw random birth-orders
\end_layout

\begin_layout Plain Layout

dat$first <- rbinom(n = N, size = 1, prob = .4)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

## Now that we have our multiple predictors, we 
\end_layout

\begin_layout Plain Layout

## specify a model to generate outcomes (child's IQ) 
\end_layout

\begin_layout Plain Layout

## with random sampling error.
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

stde <- 9
\end_layout

\begin_layout Plain Layout

b <- c(-3, 5, .5, .5)
\end_layout

\begin_layout Plain Layout

## parameters designed so child IQ is average of parents
\end_layout

\begin_layout Plain Layout

dat$IQnoe <- b[1] + b[2]*dat$first + b[3]*dat$dadIQ + b[4]*dat$momIQ 
\end_layout

\begin_layout Plain Layout

dat$IQ <- dat$IQnoe + rnorm(N, m = 0, sd = stde)
\end_layout

\begin_layout Plain Layout

dat$IQ <- round(dat$IQ)
\end_layout

\begin_layout Plain Layout

head(dat)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

## Do sample statistics match data generator parameters?
\end_layout

\begin_layout Plain Layout

mod0 <- lm(IQ ~ first + momIQ + dadIQ, data = dat)
\end_layout

\begin_layout Plain Layout

summary(mod0)
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}[allowframebreaks,containsverbatim]
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{Anticipate Data Output Requirements}
\end_layout

\end_inset

Monte Carlo methods can be used to check the power simultaneously for all
 effects (i.e., each slope estimates).
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<iq200>>=
\end_layout

\begin_layout Plain Layout

## Inspect data output, figure out what we want.
\end_layout

\begin_layout Plain Layout

## 
\end_layout

\begin_layout Plain Layout

summary(mod0)$coef
\end_layout

\begin_layout Plain Layout

## get p values
\end_layout

\begin_layout Plain Layout

summary(mod0)$coef[2:4, 4]
\end_layout

\begin_layout Plain Layout

## check whether they meet significance criterion
\end_layout

\begin_layout Plain Layout

alpha <- .05
\end_layout

\begin_layout Plain Layout

alpha
\end_layout

\begin_layout Plain Layout

summary(mod0)$coef[2:4, 4] < alpha
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}[allowframebreaks,containsverbatim]
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{Data Generator Program}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
def
\backslash
Rsize{
\backslash
scriptsize}
\end_layout

\begin_layout Plain Layout

<<iq300>>=
\end_layout

\begin_layout Plain Layout

makeData <- function(rep, N, R, stde = 9, b = c(-3, 5, .5, .5)) {
\end_layout

\begin_layout Plain Layout

    require(rockchalk) # will load the package if it's not already loaded
\end_layout

\begin_layout Plain Layout

    IQ.cor <- lazyCor(R, 2)
\end_layout

\begin_layout Plain Layout

    IQ.M <- c(dadIQ = 100, momIQ = 100)
\end_layout

\begin_layout Plain Layout

    IQ.SD <- c(15, 15)
\end_layout

\begin_layout Plain Layout

    IQ.cov <- diag(c(15, 15)) %*% IQ.cor %*% diag(c(15, 15))
\end_layout

\begin_layout Plain Layout

    dat <- mvrnorm(n = N, mu = IQ.M, Sigma = IQ.cov)
\end_layout

\begin_layout Plain Layout

    dat <- as.data.frame(round(dat))
\end_layout

\begin_layout Plain Layout

    dat$first <- rbinom(n = N, size = 1, prob = .4)
\end_layout

\begin_layout Plain Layout

    dat$IQnoe <- b[1] + b[2]*dat$first + b[3]*dat$dadIQ + b[4]*dat$momIQ
 
\end_layout

\begin_layout Plain Layout

    dat$IQ <- dat$IQnoe + rnorm(N, m = 0, sd = stde)
\end_layout

\begin_layout Plain Layout

    dat$IQ <- round(dat$IQ)
\end_layout

\begin_layout Plain Layout

    dat$rep <- rep
\end_layout

\begin_layout Plain Layout

    dat
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

## Test it once
\end_layout

\begin_layout Plain Layout

set.seed(123)
\end_layout

\begin_layout Plain Layout

dat <- makeData(1, N = 20, R = .3)
\end_layout

\begin_layout Plain Layout

head(dat)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

## To analyze that data and return rejection decisions
\end_layout

\begin_layout Plain Layout

getDecision <- function(data, alpha = .05) {
\end_layout

\begin_layout Plain Layout

    ## run a regression on sample data
\end_layout

\begin_layout Plain Layout

    mod <- lm(IQ ~ first + momIQ + dadIQ, data = data)
\end_layout

\begin_layout Plain Layout

    ## return decisions about whether null was rejected for each slope
\end_layout

\begin_layout Plain Layout

    summary(mod)$coef[2:4, 4] < alpha
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

## Test it once (on the data we just generated)
\end_layout

\begin_layout Plain Layout

getDecision(data = dat)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

## Test it on 5 replications to see the format of the output
\end_layout

\begin_layout Plain Layout

dataList <- lapply(1:5, makeData, N = 100, R = 0.30)
\end_layout

\begin_layout Plain Layout

lapply(dataList, head)
\end_layout

\begin_layout Plain Layout

do.call(rbind, lapply(dataList, getDecision))
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

## Define a function that gets rejections for nReps replications per
\end_layout

\begin_layout Plain Layout

## condition
\end_layout

\begin_layout Plain Layout

runCond <- function(nReps, N, R) {
\end_layout

\begin_layout Plain Layout

    ## generate nReps data sets
\end_layout

\begin_layout Plain Layout

    dataList <- lapply(1:nReps, makeData, N = N, R = R)
\end_layout

\begin_layout Plain Layout

    ## run regression and get rejection decisions for each data set
\end_layout

\begin_layout Plain Layout

    out <- data.frame(do.call(rbind, lapply(dataList, getDecision)))
\end_layout

\begin_layout Plain Layout

    ## record conditions
\end_layout

\begin_layout Plain Layout

    out$N <- N
\end_layout

\begin_layout Plain Layout

    out$R <- R
\end_layout

\begin_layout Plain Layout

    ## return results
\end_layout

\begin_layout Plain Layout

    out
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

## Test it on 10 replications
\end_layout

\begin_layout Plain Layout

runCond(nReps = 10, N = 100, R = .3)
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}[allowframebreaks,containsverbatim]
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{Build a condition object}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<iq310>>=
\end_layout

\begin_layout Plain Layout

## Using a Monte Carlo design, we can calculate power across sample
\end_layout

\begin_layout Plain Layout

## sizes as the proportion of cases where the null was rejected in
\end_layout

\begin_layout Plain Layout

## each condition.
\end_layout

\begin_layout Plain Layout

cond.N <- seq(from = 20, to = 150, by = 10)
\end_layout

\begin_layout Plain Layout

cond.N
\end_layout

\begin_layout Plain Layout

cond.R <- c(0.30) # for now, don't vary the correlation between predictors
\end_layout

\begin_layout Plain Layout

conds <- expand.grid(N = cond.N, R = cond.R)
\end_layout

\begin_layout Plain Layout

conds$nReps <- 1000
\end_layout

\begin_layout Plain Layout

conds
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}[allowframebreaks,containsverbatim]
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{Run a simulation}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<iq320>>=
\end_layout

\begin_layout Plain Layout

## Run 1000 t tests in each condition to see how often the null is
\end_layout

\begin_layout Plain Layout

## rejected
\end_layout

\begin_layout Plain Layout

set.seed(123)
\end_layout

\begin_layout Plain Layout

out <- apply(conds, MARGIN = 1,
\end_layout

\begin_layout Plain Layout

             FUN = function(x) do.call(runCond, as.list(x)))
\end_layout

\begin_layout Plain Layout

out <- do.call(rbind, out)
\end_layout

\begin_layout Plain Layout

head(out)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

## TRUE == 1 and FALSE == 0, so the mean of each outcome is the
\end_layout

\begin_layout Plain Layout

## proportion of samples for which the null was rejected (in each
\end_layout

\begin_layout Plain Layout

## condition).
\end_layout

\begin_layout Plain Layout

rates <- aggregate(cbind(first, momIQ, dadIQ) ~ N, data = out, mean)
\end_layout

\begin_layout Plain Layout

rates
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}[allowframebreaks,containsverbatim]
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{Did we find out anything?}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<iq340, fig=T>>=
\end_layout

\begin_layout Plain Layout

## plot power by sample size
\end_layout

\begin_layout Plain Layout

plot(first ~ N, data = rates, type = "l", lwd = 2, ylim = 0:1)
\end_layout

\begin_layout Plain Layout

abline(h = .8, col = "darkgreen", lty = "dashed")
\end_layout

\begin_layout Plain Layout

lines(momIQ ~ N, data = rates, col = "red", lwd = 2, lty = 2)
\end_layout

\begin_layout Plain Layout

lines(dadIQ ~ N, data = rates, col = "blue", lwd = 2, lty = 3)
\end_layout

\begin_layout Plain Layout

legend("bottomright", legend = c("first", "momIQ", "dadIQ"),
\end_layout

\begin_layout Plain Layout

       col = c("black" , "red", "blue"), lty = c(1,2,3))
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Enumerate
What sample size is required to detect the effect of mom's IQ at least 80%
 of the time?
\end_layout

\begin_layout Enumerate
Dad's IQ? 
\end_layout

\begin_layout Enumerate
First-born status? 
\end_layout

\begin_layout Standard
Do we need to add more sample size conditions?
\end_layout

\begin_layout Standard
More complete power analyses might take into more population parameters,
 such as the correlation among other predictors, or the effects (slopes)
 of each predictor, or the variance of the random errors, or whether interaction
s exist, etc.
 
\end_layout

\begin_layout Standard
The function above already allows you to manipulate the correlation between
 predictors, but you can add arguments to manipulate other characteristics
 of importance.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Section
Conclusions
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{Cookbook.
 And Beyond!}
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Power analysis is easy for simple problems, we have a good deal of experience
 with 1-predictor models with simple designs
\end_layout

\begin_layout Itemize
More complicated models don't fit into the easy-to-use cookbooks
\end_layout

\begin_layout Itemize
Monte Carlo Simulation can be a way to understand the ability of a proposed
 study to detect statistically significant findings.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}[allowframebreaks]
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{Can't live with it.
 Can't live without it}
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Power analysis involves guessing about parameters and distributions of predictor
s
\end_layout

\begin_layout Itemize
Much of the work seems onerous or silly to researchers, who say they 
\begin_inset Quotes eld
\end_inset

just don't know,
\begin_inset Quotes erd
\end_inset

 yet
\end_layout

\begin_layout Itemize
Nevertheless, project planners (and funders) need to be assured that the
 study will, if correctly executed, recover statistically significant evidence.
\end_layout

\begin_layout Itemize
If a study ever concludes with a comment like
\end_layout

\begin_deeper
\begin_layout Quote
We did not find statistically significant differences between groups, but
 we still believe there are effects worth finding.
 The likely explanation for our difficulty is the small number of participants
 in each group.
\end_layout

\begin_layout Standard
we should blame the people who carried out the study for poor planning and
 inadequate power analysis.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}[allowframebreaks]
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{References}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\align left
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "../../R"
options "apalike2"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frame}[containsverbatim, allowframebreaks]
\end_layout

\begin_layout Plain Layout


\backslash
frametitle{Session}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<sess10>>=
\end_layout

\begin_layout Plain Layout

sessionInfo()
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<opts20, include=F>>=
\end_layout

\begin_layout Plain Layout

## Don't delete this.
 It puts the interactive session options
\end_layout

\begin_layout Plain Layout

## back the way they were.
 If this is compiled within a session
\end_layout

\begin_layout Plain Layout

## it is vital to do this.
\end_layout

\begin_layout Plain Layout

options(opts.orig)
\end_layout

\begin_layout Plain Layout

options(par.orig)
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{frame}
\end_layout

\end_inset


\end_layout

\end_body
\end_document
